{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un modèle prédictif simple avec régression linéaire..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons explorer comment créer un modèle de régression linéaire simple en utilisant Python. \n",
    "\n",
    "#### Pour ce live-coding, nous utiliserons un jeu de données qui recensent les salaires, l'âge et l'expérience de chaque individus pour prédire les salaires en fonctions des autres variables.\n",
    "\n",
    "### Contexte :\n",
    "\n",
    "La régression linéaire est l'une des techniques les plus fondamentales et les plus couramment utilisées en machine learning et en statistique. Elle permet de modéliser la relation entre une variable ou des variables indépendantes (ou prédictrice) et une variable dépendante (ou cible) en ajustant une ligne droite (ou hyperplan en cas de régression linéaire multiple) aux données observées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'objectif de ce notebook pour ce live-coding est de :\n",
    "\n",
    "##### De montrer comment entraîner un modèle de régression linéaire simple, et de comprendre comment la prédiction s'opère.\n",
    "\n",
    "##### Let's code !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprendre la régression linéaire..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commençons par importer les packages nécessaires et le jeu de donnée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des packages nécessaires pour explorer le jeu de donnée :\n",
    "\n",
    "import numpy as np # Utile pour les principes de vectorisations\n",
    "import pandas as pd # Nous allons manipuler les données sur un objet dataframe\n",
    "import matplotlib.pyplot as plt # Utile pour visualiser les données\n",
    "import seaborn as sns # Également utile pour visualiser les données\n",
    "\n",
    "# Packages permettant de faire du machine learning :\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Nous permet de diviser un dataframe en 'train' et 'test'\n",
    "from sklearn.linear_model import LinearRegression # Nous allons pouvoir avec ce module, créer la fonction de la régression linéaire\n",
    "from sklearn.metrics import mean_squared_error, r2_score # Ce sont les métriques qui évaluerons notre modèle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # C'est pour initialiser la normalisation de nos données\n",
    "from math import sqrt # Ce package permet de manipuler les modèles de régression si nécessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de notre jeu de donnée :\n",
    "\n",
    "df_income = pd.read_csv('income.csv')\n",
    "df_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorons la donnée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Méthodes classique permettant de comprendre notre jeu de donnée :\n",
    "\n",
    "print(f\"Le dataframe à {df_income.shape[0]} éléments sur la première dimensions et {df_income.shape[1]} sur la deuxième dimension.\")\n",
    "print(f\"Les colonnes sont: l'{df_income.columns[0]}, l'{df_income.columns[1]} et l'{df_income.columns[2]}.\")\n",
    "print(\"\\nLes types de données:\")\n",
    "print(df_income.info())\n",
    "print(\"\\n Les statistiques descriptives:\")\n",
    "print(df_income.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Le jeu de donnée ne présente pas de valeurs manquantes, nos variables comportent des données de type integers.\n",
    "- Nous pouvons nous attarder sur les métriques principales, la moyenne, la médiane ainsi que l'écart-type de nos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code permettant de visualiser la distribution des âges :\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df_income['age'], kde=True, bins=5)\n",
    "plt.title('Distribution des âges')\n",
    "\n",
    "# Code permettant de visualiser la distribution de l'experience :\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df_income['experience'], kde=True, bins=5)\n",
    "plt.title('Distribution de l\\'expérience')\n",
    "\n",
    "# Code permettant de visualiser la distribution des salaires :\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df_income['income'], kde=True, bins=5)\n",
    "plt.title('Distribution des revenus')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Nous observons une certaines similarités dans la distribution des variables, grâce au kernel density estimate (kde).\n",
    "- Nous pouvons déjà nous poser la question de l'influence des variables prédictrices sur notre variable cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La méthode '.pairplot()' est très utile pour visualiser les relations linéaires entre les variables :\n",
    "\n",
    "sns.pairplot(df_income) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- On constate une linéarité forte entre les salaires et l'expérience, la linéarité est plus faible entre les salaires et l'âge.\n",
    "\n",
    "- Nous pouvons donc affirmer que les variables prédictrices ont un pouvoir d'influence significative sur notre variable cible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des coefficients de corrélation des variables de notre jeu de donnée\n",
    "\n",
    "correlation_income = df_income.corr()\n",
    "sns.heatmap(correlation_income, annot=True, fmt=\".2%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- On observe une très forte corrélation positive de 98% entre l'expérience et le salaire, ce qui indique que l'expérience est un facteur déterminant majeur dans la variation des salaires. La corrélation entre l'âge et le salaire est de 53%, indiquant que l'âge a une influence modérée mais moins directe sur le salaire comparé à l'expérience.\n",
    "\n",
    "- La corrélation relativement plus faible entre l'âge et le salaire, comparée à celle entre l'expérience et le salaire, montre que l'expérience est un prédicteur beaucoup plus significatif des salaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C'est le moment d'initialiser notre modèle de régression !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il est temps de diviser notre jeu de donnée en quatre :\n",
    "\n",
    "features = ['age', 'experience'] # Représente les variables prédictrices (qui explique le salaire)\n",
    "target = 'income' # Représente le salaire, c'est notre variable cible\n",
    "\n",
    "X = df_income[features] # Xs est un dataframe contenant deux colonnes\n",
    "y = df_income[target] # y est un dataframe qui contient une colonne\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # C'est ici qu'on vient effectuer le split des données\n",
    "\n",
    "print(f'Taille de X_train: {X_train.shape}, taille de X_test: {X_test.shape}, taille de y_train: {y_train.shape}, taille de y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- On commence par diviser notre jeu de donnée en quatre parties :\n",
    "\n",
    "    - On isole la variable cible des variables prédictrices.\n",
    "\n",
    "    - On viens ensuite diviser notre jeu de données en deux, de façon aléatoire :\n",
    "    \n",
    "        - 80% des données sont réparties dans deux variables d'entraînement, X_train et y_train.\n",
    "    \n",
    "        - 20% des données sont réparties dans deux variables d'evaluation, X_test et y_test.\n",
    "\n",
    "- On constate la bonne répartition des données dans chacunes de nos variables !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle de régression linéaire :\n",
    "\n",
    "model = LinearRegression() # On initialise la fonction de régression (f(x)), dans une variable\n",
    "\n",
    "model.fit(X_train, y_train) # Entraînement du modèle sur les données d'entraînement\n",
    "\n",
    "y_pred = model.predict(X_test) # Prédiction sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- On vient initialiser dans une variable la fonction de régression pour pouvoir appliquer des méthodes dessus.\n",
    "\n",
    "- Justement, on applique sur la variable la méthode '.fit()' :\n",
    "\n",
    "    - On vient entraîner le modèle sur nos variables d'entraînement, X_train et y_train.\n",
    "\n",
    "- On applique la méthode '.predict()' sur notre variable d'évaluation, X_test :\n",
    "\n",
    "    - Cette méthode permet de créer 4 valeurs prédites en fonctions des variables prédictrices dans X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du coefficient de détermination R² : \n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Coefficient de détermination: {round(r2, 4)}') # Ce coefficicent indique la proportion de la variance des salaires qui est expliquée par le modèle\n",
    "print(f'la précision du modèle en terme de prédiction est de : {round(r2, 2) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Un R² proche de 1 (ou 100%) suggère que le modèle explique bien la variabilité des salaires en fonction de l'âge et de l'expérience.\n",
    "\n",
    "- Toutefois, un R² très élevé pourrait aussi indiquer un risque d'overfitting si le modèle est trop spécifique aux données d'entraînement, ce qui pourrait réduire sa capacité à généraliser sur de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur de nouvelles données :\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    'age': [47, 50, 28, 19],\n",
    "    'experience': [12, 20, 7, 2]\n",
    "})\n",
    "\n",
    "new_predictions = model.predict(df_predictions) # Prédiction des revenus avec les nouvelles données\n",
    "\n",
    "df_predictions['predicted_income'] = new_predictions.round() # Affichage des prédictions\n",
    "\n",
    "df_new_income = pd.concat([df_income, df_predictions]) # Concaténation des dataframes\n",
    "df_new_income = df_new_income.reset_index().drop(columns='index') # Réinitialisation de l'index\n",
    "display(df_new_income) # Affichage de notre jeu de données ayant les observations réelles et les observation prédites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Les nouvelles données incluent des âges de 41, 50, 28, et 30 ans avec respectivement 10, 20, 7, et 3 années d'expérience. Le modèle de régression linéaire est utilisé pour prédire les revenus basés sur ces nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6)) # paramétrage de la taille de l'output\n",
    "\n",
    "# Premier sous-graphique montrant la relation entre les revenus prédits et l'expérience :\n",
    "\n",
    "plt.subplot(1, 3, 2)  \n",
    "sns.scatterplot(x=df_new_income['experience'], y=df_new_income['predicted_income'])\n",
    "sns.regplot(x=df_new_income['experience'], y=df_new_income['predicted_income'], scatter=False)\n",
    "plt.xlabel('Expérience')\n",
    "plt.ylabel('Revenus prédits')\n",
    "plt.title('Revenus prédits en fonction de l\\'expérience')\n",
    "\n",
    "# Deuxième sous-graphique montrant la distribution des revenus réels et des revenus prédits :\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df_new_income['income'], kde=True, bins=10, color='blue', label='Revenus réels', alpha=0.6)\n",
    "sns.histplot(df_new_income['predicted_income'], kde=True, bins=10, color='orange', label='Revenus prédits', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.title('Distribution des revenus réels et prédits')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Malgré le fait que nous nous basons sur simplement quatres données prédites, il semble que le modèle est bien cohérent par rapport aux données des variables prédictrices !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appliquer la régression linéaire sur des données plus complexe..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcément, les jeux de données sont rarement aussi simple !\n",
    "\n",
    "Dans la première partie de notre live coding, nous avons exploré un exemple de modèle de régression linéaire sur un jeu de données relativement simple, mettant en relation les revenus prédits avec des variables telles que l'expérience et l'âge. Cependant, dans le monde réel, les jeux de données sont rarement aussi simples. \n",
    "\n",
    "##### Souvent, ils sont beaucoup plus riches et complexes, composés de multiples types de variables.\n",
    "\n",
    "Dans cette deuxième partie, nous allons plonger dans un jeu de données plus complexe et plus riche. Nous explorerons un exemple de modèle de machine learning appliqué à un jeu de données comportant à la fois des données numériques et catégorielles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = pd.read_csv('salary_prediction_data.csv')\n",
    "display(df_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement de la donnée avant d'initialiser le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- On ne traite pas les données numériques de la même façon que les données catégorielles. Ici, nos variables ont le bon type de donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Il est essentiel d'enlever les valeurs manquantes avant d'initialiser un modèle de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation les variables de notre jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Nous constatons que nos variables prédictrices ne suivent pas une distribution normale, nous favoriserons donc le normalisateur : 'MinMaxScaler()' pour elles.\n",
    "\n",
    "- Également, la relation entre nos features par rapport a notre target est difficile à déterminer. Cela reflète bien la réalité du marché et des salaires !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division de notre jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Education', 'Experience' ,'Location', 'Job_Title', 'Age', 'Gender']\n",
    "target = 'Salary'\n",
    "\n",
    "X = df_salary[features] \n",
    "y = df_salary[target] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "print(f'Taille de X_train: {X_train.shape}, taille de X_test: {X_test.shape}, taille de y_train: {y_train.shape}, taille de y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Nous remarquons la bonne répartition de nos données dans nos quatres nouveaux objets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commençons par traiter nos données numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.select_dtypes(include='number')\n",
    "\n",
    "mmscaler = MinMaxScaler() # Création d'un objet MinMaxScaler\n",
    "cols_to_nor = ['Experience', 'Age'] # Appliquer la normalisation sur ces colonnes\n",
    "\n",
    "# Normalisation de nos features avec le MinMaxScaler : \n",
    "\n",
    "X_train_nor = pd.DataFrame(mmscaler.fit_transform(X_train[cols_to_nor]), columns=cols_to_nor, index=X_train.index) # Appliquer le scaler sur l'ensemble de train\n",
    "X_test_nor = pd.DataFrame(mmscaler.transform(X_test[cols_to_nor]), columns=cols_to_nor, index=X_test.index) # Appliquer le scaler à l'ensemble de test\n",
    "display(X_test[cols_to_nor])\n",
    "display(X_test_nor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Ici, la normalisation des données nous à permis de mettre nos données à niveau pour éviter que notre modèle attribut un poid trop grand sur la variable 'Age'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement de nos variables catégorielles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_salary.select_dtypes(include='O'))\n",
    "\n",
    "print(f'Nombre de catégories différentes dans la variable genre : {df_salary['Gender'].nunique()}.')\n",
    "print(f'Nombre de catégories différentes dans la variable métier : {df_salary['Job_Title'].nunique()}.')\n",
    "print(f'Nombre de catégories différentes dans la variable zone : {df_salary['Location'].nunique()}.')\n",
    "print(f'Nombre de catégories différentes dans la variable niveau d\\'éducation : {df_salary['Education'].nunique()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever : \n",
    "- Nous constatons qu'il n'y a pas beaucoup de catégorie sur nos variables, dans le cas contraire, il est judicieux de venir sélectionner les valeurs les plus représentés de nos variables pour éviter des problèmes de dimensionnalité dans notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La méthode pandas .get_dummies() nous permet d'encoder nos variables catégorielles :\n",
    "\n",
    "X_train_enc = pd.get_dummies(X_train.select_dtypes(include='O'), columns=['Gender', 'Job_Title', 'Location', 'Education'], drop_first=True).astype(int)\n",
    "X_test_enc = pd.get_dummies(X_test.select_dtypes(include='O'), columns=['Gender', 'Job_Title', 'Location', 'Education'], drop_first=True).astype(int)\n",
    "display(X_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "- Nous constatons que le code n'a pas générer une nouvelle colonnes pour les premières catégories de nos variables, cela s'explique par le paramètre 'drop_first'. En effet, ce paramètre supprime intentionnellement la première catégorie de chaque variable catégorielle pour éviter la multicolinéarité.\n",
    "\n",
    "- Ainsi, si Gender_Male est 0, cela indique implicitement que le genre est Female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusions de nos DataFrames normalisés et encodés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des jeux de données pour nourrir notre modèle de régression :\n",
    "\n",
    "X_train_clean = pd.merge(X_train_enc, X_train_nor, left_index=True, right_index=True)\n",
    "X_test_clean = pd.merge(X_test_enc, X_test_nor, left_index=True, right_index=True)\n",
    "display(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la variable target aux ensembles d'entraînement et de test :\n",
    "\n",
    "df_train_clean = pd.merge(X_train_clean, y_train, left_index=True, right_index=True)\n",
    "df_test_clean = pd.merge(X_test_clean, y_test, left_index=True, right_index=True)\n",
    "display(df_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point à relever :\n",
    "- Nous remarquons que nos données normalisées, nos données encodées et notre target variable ont été fusionnées correctement.\n",
    "\n",
    "- Les étapes de normalisation et d'encodage des données permettent aux modèles de Machine Learning de comprendre les tendances mathématiques sous-jacentes de notre jeu de données.\n",
    "\n",
    "- La normalisation assure que les différentes caractéristiques sont sur la même échelle, l'encodage des variables catégorielles transforme les catégories en un format numérique, facilement interprétable pour les modèles prédictifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation du modèle linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-séparation des features et de la variable target pour notre modèle :\n",
    "\n",
    "X_train_ml = df_train_clean.drop(columns=['Salary'])\n",
    "X_test_ml = df_test_clean.drop(columns=['Salary'])\n",
    "y_train_ml = df_train_clean['Salary']\n",
    "y_test_ml = df_test_clean['Salary']\n",
    "\n",
    "model = LinearRegression() # Création d'un objet LinearRegression()\n",
    "\n",
    "model.fit(X_train_ml, y_train_ml) # Entraînement du modèle sur nos données qui y sont destinées\n",
    "y_pred = model.predict(X_test_ml) # Prédictions sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle :\n",
    "\n",
    "mse = mean_squared_error(y_test_ml, y_pred)\n",
    "rmse = sqrt(mean_squared_error(y_test_ml, y_pred))\n",
    "r2 = r2_score(y_test_ml, y_pred)\n",
    "\n",
    "print(f'L\\'erreur quadratique moyenne ou MSE est égale à : {round(mse, 2)}.')\n",
    "print(f'La racine carré du MSE ou RMSE est égale à : {round(rmse, 2)}.')\n",
    "print(f'La performance du modèle pour prédire les salaires, donnée par le coefficient de détermination est de R² : {round(r2 * 100, 2)}%.')\n",
    "\n",
    "# Affichage des coefficients du modèle :\n",
    "\n",
    "coefficients = pd.DataFrame(model.coef_, X_train_ml.columns, columns=['Coefficient'])\n",
    "coefficients = coefficients.sort_values(by='Coefficient', ascending=False).round(2)\n",
    "display(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points à relever :\n",
    "\n",
    "- Le RMSE est la racine carrée du MSE. C'est une mesure plus interprétable que le MSE car elle est dans la même unité que la variable cible, soit en dollars. Un RMSE de 10,295.45 indique que, en moyenne, les prédictions de salaire du modèle sont à environ 10,295 dollars de la valeur réelle. Les coefficients sont également intéressants.\n",
    "\n",
    "- Les valeurs de MSE et RMSE, bien qu'élevées, sont cohérentes avec la nature des données salariales qui peuvent varier de manière significative.\n",
    "\n",
    "- La régression linéaire montre de bonnes performances avec un R² élevé, indiquant qu'elle explique bien les variations de salaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Que faut t-il faire ensuite ?\n",
    "\n",
    "#### Durant ce live coding, nous avons tenté de comprendre comment un modèle de régression linéaire fonctionnait.\n",
    "\n",
    "### Mais quelles sont les prochaines étapes du Data Scientist après avoir constaté le R² et la MSE ?\n",
    "\n",
    "### Il va falloir qu'il affûte son modèle !\n",
    "\n",
    "Pour cela, il peut identifier les features qui ont le plus d'impact sur la prédiction des salaires. Il va donc utiliser des techniques comme la réduction de dimensions qui lui permettra de e débarrasser des features qui nous ralentissent et ne servent à rien.\n",
    "\n",
    "##### Mais il va surtout tester le modèle sur plusieurs ensembles de données différents...\n",
    "\n",
    "Pour s'assurer qu'il n'apprend pas par coeur les données et qu'il généralise bien à de nouvelles situations. \n",
    "\n",
    "### Il va ensuite déployer sont modèle de Machine Learning !\n",
    "\n",
    "Il va choisir la plateforme idéale pour héberger sont modèle, en fonction de ses besoins en termes de puissance, de scalabilité et de coûts. Des options populaires incluent les plateformes cloud comme Google Cloud Platform, Amazon Web Services ou Microsoft Azure, ou encore des solutions sur site comme Docker ou Kubernetes.\n",
    "\n",
    "Plus précisement, il va enregistrer sont modèle dans un format adéquat pour le déploiement, comme un fichier pickle. Il va ensuite créer un script ou une application pour charger le modèle, faire des prédictions et interpréter les résultats.\n",
    "\n",
    "### Mais à la base des prédictions salariales des différents sites, il y a un script Python qui ressemble un peu au nôtre !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
